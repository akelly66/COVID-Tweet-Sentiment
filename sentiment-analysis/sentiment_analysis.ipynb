{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of COVID-19 Tweets: When did the Public Panic Set In? Part 4: Supervised Classification Modeling\n",
    "\n",
    "    Notebook by Allison Kelly - allisonkelly42@gmail.com\n",
    "    \n",
    "This notebook is preceded by parts <a href=\"https://github.com/akelly66/COVID-Tweet-Sentiment/blob/master/tweet-scraping/Twitter-API-Scraping.ipynb\">1</a>, <a href=\"https://github.com/akelly66/COVID-Tweet-Sentiment/blob/master/text-processing/NLP-Text-Processing.ipynb\">2</a> and <a href=\"https://github.com/akelly66/COVID-Tweet-Sentiment/blob/master/EDA/tweet-EDA.ipynb\">3</a>. Part 4 will focus on the modeling portion, but is still very much in ins infancy. Markdown cells and complete documentation to come. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:36:59.169955Z",
     "start_time": "2020-09-24T00:36:55.081996Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from nltk import word_tokenize\n",
    "from ast import literal_eval\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:37:46.538655Z",
     "start_time": "2020-09-24T00:36:59.173978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[switchfoot, httptwitpiccom, 2y1zl, awww, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[upset, cant, update, facebook, texting, might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[kenichan, dived, many, time, ball, managed, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[whole, body, feel, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[nationwideclass, behaving, im, mad, cant, see]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                   processed_tweets\n",
       "0         0  [switchfoot, httptwitpiccom, 2y1zl, awww, that...\n",
       "1         0  [upset, cant, update, facebook, texting, might...\n",
       "2         0  [kenichan, dived, many, time, ball, managed, s...\n",
       "3         0             [whole, body, feel, itchy, like, fire]\n",
       "4         0    [nationwideclass, behaving, im, mad, cant, see]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweets = pd.read_csv('Data/processed_train.csv', \n",
    "                       usecols=['polarity', 'processed_tweets'],\n",
    "                       # Converting string to list\n",
    "                       converters={\"processed_tweets\": literal_eval})\n",
    "train_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:37:46.556077Z",
     "start_time": "2020-09-24T00:37:46.543345Z"
    }
   },
   "outputs": [],
   "source": [
    "target = train_tweets['polarity']\n",
    "data = train_tweets['processed_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:37:47.561117Z",
     "start_time": "2020-09-24T00:37:46.570678Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42, test_size=.20)\n",
    "\n",
    "train_df = pd.concat([X_train, y_train], axis=1) \n",
    "test_df = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:37:47.621804Z",
     "start_time": "2020-09-24T00:37:47.568811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    640506\n",
       "4    639494\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:37:47.768539Z",
     "start_time": "2020-09-24T00:37:47.637661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5017\n",
       "0    4983\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = train_df.sample(n=10000, random_state = 42)\n",
    "train_sample.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:37:47.818410Z",
     "start_time": "2020-09-24T00:37:47.771729Z"
    }
   },
   "outputs": [],
   "source": [
    "all_words_list = [item for sublist in train_sample.processed_tweets for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:37:47.855080Z",
     "start_time": "2020-09-24T00:37:47.822164Z"
    }
   },
   "outputs": [],
   "source": [
    "total_vocab = set(all_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:37:47.891031Z",
     "start_time": "2020-09-24T00:37:47.858590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18750"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(all_words_list))\n",
    "len(total_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:37:47.938416Z",
     "start_time": "2020-09-24T00:37:47.909228Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:37:50.015252Z",
     "start_time": "2020-09-24T00:37:47.942300Z"
    }
   },
   "outputs": [],
   "source": [
    "train_tweet_list = X_train.apply(('').join)\n",
    "test_tweet_list = X_test.apply(('').join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:38:08.509045Z",
     "start_time": "2020-09-24T00:37:50.018369Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_train = vectorizer.fit_transform(train_tweet_list)\n",
    "tfidf_test = vectorizer.transform(test_tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:38:08.539284Z",
     "start_time": "2020-09-24T00:38:08.511776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280000, 1259141)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:48:02.620668Z",
     "start_time": "2020-09-24T00:48:02.607474Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:38:09.249056Z",
     "start_time": "2020-09-24T00:38:08.599461Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "nb_train_preds = nb_classifier.predict(tfidf_train)\n",
    "nb_test_preds = nb_classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T00:47:02.628573Z",
     "start_time": "2020-09-24T00:47:02.359578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Training Accuracy: 0.9961 \t\t Testing Accuracy: 0.5118\n"
     ]
    }
   ],
   "source": [
    "nb_train_score = accuracy_score(y_train, nb_train_preds)\n",
    "nb_test_score = accuracy_score(y_test, nb_test_preds)\n",
    "print(\"Multinomial Naive Bayes\")\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(nb_train_score, nb_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-24T00:48:06.574Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_classifier.fit(tfidf_train, y_train)\n",
    "rf_train_preds = rf_classifier.predict(tfidf_train)\n",
    "rf_test_preds = rf_classifier.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-09-24T00:48:07.427Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_train_score = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_score = accuracy_score(y_test, rf_test_preds)\n",
    "print('Random Forest')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(rf_train_score, rf_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
