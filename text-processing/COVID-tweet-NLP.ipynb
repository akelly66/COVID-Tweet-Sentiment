{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of COVID-19 Tweets: When did the Public Panic Set In?\n",
    "\n",
    "    Notebook by Allison Kelly - allisonkelly42@gmail.com\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:10.548298Z",
     "start_time": "2020-06-12T18:26:08.026565Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Generic Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, time\n",
    "\n",
    "# Get JSON\n",
    "import json\n",
    "\n",
    "# Text preprocessing libraries\n",
    "import string\n",
    "import contractions\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Data\n",
    "\n",
    "View method to obtain data <a href=\"https://github.com/akelly66/COVID-Tweet-Sentiment/blob/master/tweet-scraping/COVID-tweets-true.ipynb\">here</a>. <br>\n",
    "<br>The tweet query parameters were as follows:\n",
    "\n",
    "- <b>Keywords: </b> \"coronavirus OR Wuhan virus OR 2019-nCoV OR China flu\"<br>\n",
    "- <b>Date Range: </b> 28 Jan 2020 - 03 Feb 2020<br>\n",
    "- <b>Location:</b> United States of America<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:11.235241Z",
     "start_time": "2020-06-12T18:26:10.553827Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>truncated</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>...</th>\n",
       "      <th>lang</th>\n",
       "      <th>matching_rules</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>quoted_status_permalink</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>extended_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Feb 02 23:59:59 +0000 2020</td>\n",
       "      <td>1224120307717410816</td>\n",
       "      <td>1224120307717410816</td>\n",
       "      <td>RT @QuestForSense: Amazing Timelapse as China ...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'tag': None}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>1224120306668883971</td>\n",
       "      <td>1224120306668883971</td>\n",
       "      <td>RT @selinawangtv: Bloomberg SCOOP on #coronavi...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'tag': None}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>1224120305431375872</td>\n",
       "      <td>1224120305431375872</td>\n",
       "      <td>RT @Marfoogle: I have become Ill. But no worri...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'tag': None}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>1224120305322467329</td>\n",
       "      <td>1224120305322467329</td>\n",
       "      <td>RT @NPRHealth: U.S. Hospitals Unprepared For A...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'tag': None}]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>1224120304731029504</td>\n",
       "      <td>1224120304731029504</td>\n",
       "      <td>RT @SecAzar: At this time, the risk to America...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'tag': None}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.223347e+18</td>\n",
       "      <td>1.223347e+18</td>\n",
       "      <td>{'created_at': 'Fri Jan 31 20:47:02 +0000 2020...</td>\n",
       "      <td>{'url': 'https://t.co/eb4YN1H7QN', 'expanded':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "1  Sun Feb 02 23:59:59 +0000 2020  1224120307717410816  1224120307717410816   \n",
       "2  Sun Feb 02 23:59:58 +0000 2020  1224120306668883971  1224120306668883971   \n",
       "3  Sun Feb 02 23:59:58 +0000 2020  1224120305431375872  1224120305431375872   \n",
       "4  Sun Feb 02 23:59:58 +0000 2020  1224120305322467329  1224120305322467329   \n",
       "5  Sun Feb 02 23:59:58 +0000 2020  1224120304731029504  1224120304731029504   \n",
       "\n",
       "                                                text  \\\n",
       "1  RT @QuestForSense: Amazing Timelapse as China ...   \n",
       "2  RT @selinawangtv: Bloomberg SCOOP on #coronavi...   \n",
       "3  RT @Marfoogle: I have become Ill. But no worri...   \n",
       "4  RT @NPRHealth: U.S. Hospitals Unprepared For A...   \n",
       "5  RT @SecAzar: At this time, the risk to America...   \n",
       "\n",
       "                                              source  truncated  \\\n",
       "1  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "2  <a href=\"http://twitter.com/#!/download/ipad\" ...      False   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "4  <a href=\"http://twitter.com/#!/download/ipad\" ...      False   \n",
       "5  <a href=\"http://twitter.com/download/android\" ...      False   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "1                    NaN                        NaN                  NaN   \n",
       "2                    NaN                        NaN                  NaN   \n",
       "3                    NaN                        NaN                  NaN   \n",
       "4                    NaN                        NaN                  NaN   \n",
       "5                    NaN                        NaN                  NaN   \n",
       "\n",
       "   in_reply_to_user_id_str  ... lang   matching_rules possibly_sensitive  \\\n",
       "1                      NaN  ...   en  [{'tag': None}]                NaN   \n",
       "2                      NaN  ...   en  [{'tag': None}]                NaN   \n",
       "3                      NaN  ...   en  [{'tag': None}]                NaN   \n",
       "4                      NaN  ...   en  [{'tag': None}]              False   \n",
       "5                      NaN  ...   en  [{'tag': None}]                NaN   \n",
       "\n",
       "  quoted_status_id quoted_status_id_str  \\\n",
       "1              NaN                  NaN   \n",
       "2              NaN                  NaN   \n",
       "3              NaN                  NaN   \n",
       "4              NaN                  NaN   \n",
       "5     1.223347e+18         1.223347e+18   \n",
       "\n",
       "                                       quoted_status  \\\n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5  {'created_at': 'Fri Jan 31 20:47:02 +0000 2020...   \n",
       "\n",
       "                             quoted_status_permalink  display_text_range  \\\n",
       "1                                                NaN                 NaN   \n",
       "2                                                NaN                 NaN   \n",
       "3                                                NaN                 NaN   \n",
       "4                                                NaN                 NaN   \n",
       "5  {'url': 'https://t.co/eb4YN1H7QN', 'expanded':...                 NaN   \n",
       "\n",
       "   extended_tweet  extended_entities  \n",
       "1             NaN                NaN  \n",
       "2             NaN                NaN  \n",
       "3             NaN                NaN  \n",
       "4             NaN                NaN  \n",
       "5             NaN                NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"expanded_query_tweets.csv\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df.query(\"lang == 'en'\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:11.352496Z",
     "start_time": "2020-06-12T18:26:11.242113Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2375\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2375 entries, 1 to 4396\n",
      "Data columns (total 36 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   created_at                 2375 non-null   object \n",
      " 1   id                         2375 non-null   int64  \n",
      " 2   id_str                     2375 non-null   int64  \n",
      " 3   text                       2375 non-null   object \n",
      " 4   source                     2375 non-null   object \n",
      " 5   truncated                  2375 non-null   bool   \n",
      " 6   in_reply_to_status_id      108 non-null    float64\n",
      " 7   in_reply_to_status_id_str  108 non-null    float64\n",
      " 8   in_reply_to_user_id        117 non-null    float64\n",
      " 9   in_reply_to_user_id_str    117 non-null    float64\n",
      " 10  in_reply_to_screen_name    112 non-null    object \n",
      " 11  user                       2375 non-null   object \n",
      " 12  geo                        0 non-null      object \n",
      " 13  coordinates                0 non-null      object \n",
      " 14  place                      11 non-null     object \n",
      " 15  contributors               0 non-null      float64\n",
      " 16  retweeted_status           1929 non-null   object \n",
      " 17  is_quote_status            2375 non-null   bool   \n",
      " 18  quote_count                2375 non-null   int64  \n",
      " 19  reply_count                2375 non-null   int64  \n",
      " 20  retweet_count              2375 non-null   int64  \n",
      " 21  favorite_count             2375 non-null   int64  \n",
      " 22  entities                   2375 non-null   object \n",
      " 23  favorited                  2375 non-null   bool   \n",
      " 24  retweeted                  2375 non-null   bool   \n",
      " 25  filter_level               2375 non-null   object \n",
      " 26  lang                       2375 non-null   object \n",
      " 27  matching_rules             2375 non-null   object \n",
      " 28  possibly_sensitive         663 non-null    object \n",
      " 29  quoted_status_id           189 non-null    float64\n",
      " 30  quoted_status_id_str       189 non-null    float64\n",
      " 31  quoted_status              163 non-null    object \n",
      " 32  quoted_status_permalink    163 non-null    object \n",
      " 33  display_text_range         190 non-null    object \n",
      " 34  extended_tweet             174 non-null    object \n",
      " 35  extended_entities          176 non-null    object \n",
      "dtypes: bool(4), float64(7), int64(6), object(19)\n",
      "memory usage: 621.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>contributors</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.375000e+03</td>\n",
       "      <td>2.375000e+03</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.080000e+02</td>\n",
       "      <td>1.170000e+02</td>\n",
       "      <td>1.170000e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2375.000000</td>\n",
       "      <td>2375.000000</td>\n",
       "      <td>2375.000000</td>\n",
       "      <td>2375.000000</td>\n",
       "      <td>1.890000e+02</td>\n",
       "      <td>1.890000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.223425e+18</td>\n",
       "      <td>1.223425e+18</td>\n",
       "      <td>1.223349e+18</td>\n",
       "      <td>1.223349e+18</td>\n",
       "      <td>2.647967e+17</td>\n",
       "      <td>2.647967e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065684</td>\n",
       "      <td>0.134737</td>\n",
       "      <td>0.506526</td>\n",
       "      <td>1.038316</td>\n",
       "      <td>1.222812e+18</td>\n",
       "      <td>1.222812e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.450457e+14</td>\n",
       "      <td>1.450457e+14</td>\n",
       "      <td>2.524461e+14</td>\n",
       "      <td>2.524461e+14</td>\n",
       "      <td>4.316935e+17</td>\n",
       "      <td>4.316935e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009173</td>\n",
       "      <td>1.312387</td>\n",
       "      <td>6.461853</td>\n",
       "      <td>9.356226</td>\n",
       "      <td>2.511830e+15</td>\n",
       "      <td>2.511830e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.223394e+18</td>\n",
       "      <td>1.223394e+18</td>\n",
       "      <td>1.221944e+18</td>\n",
       "      <td>1.221944e+18</td>\n",
       "      <td>7.867640e+05</td>\n",
       "      <td>7.867640e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.190002e+18</td>\n",
       "      <td>1.190002e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.223394e+18</td>\n",
       "      <td>1.223394e+18</td>\n",
       "      <td>1.223345e+18</td>\n",
       "      <td>1.223345e+18</td>\n",
       "      <td>7.054162e+07</td>\n",
       "      <td>7.054162e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.222912e+18</td>\n",
       "      <td>1.222912e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.223395e+18</td>\n",
       "      <td>1.223395e+18</td>\n",
       "      <td>1.223391e+18</td>\n",
       "      <td>1.223391e+18</td>\n",
       "      <td>1.344897e+09</td>\n",
       "      <td>1.344897e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223229e+18</td>\n",
       "      <td>1.223229e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.223395e+18</td>\n",
       "      <td>1.223395e+18</td>\n",
       "      <td>1.223393e+18</td>\n",
       "      <td>1.223393e+18</td>\n",
       "      <td>7.302201e+17</td>\n",
       "      <td>7.302201e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223373e+18</td>\n",
       "      <td>1.223373e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.224120e+18</td>\n",
       "      <td>1.224120e+18</td>\n",
       "      <td>1.224119e+18</td>\n",
       "      <td>1.224119e+18</td>\n",
       "      <td>1.202716e+18</td>\n",
       "      <td>1.202716e+18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>1.224101e+18</td>\n",
       "      <td>1.224101e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id        id_str  in_reply_to_status_id  \\\n",
       "count  2.375000e+03  2.375000e+03           1.080000e+02   \n",
       "mean   1.223425e+18  1.223425e+18           1.223349e+18   \n",
       "std    1.450457e+14  1.450457e+14           2.524461e+14   \n",
       "min    1.223394e+18  1.223394e+18           1.221944e+18   \n",
       "25%    1.223394e+18  1.223394e+18           1.223345e+18   \n",
       "50%    1.223395e+18  1.223395e+18           1.223391e+18   \n",
       "75%    1.223395e+18  1.223395e+18           1.223393e+18   \n",
       "max    1.224120e+18  1.224120e+18           1.224119e+18   \n",
       "\n",
       "       in_reply_to_status_id_str  in_reply_to_user_id  \\\n",
       "count               1.080000e+02         1.170000e+02   \n",
       "mean                1.223349e+18         2.647967e+17   \n",
       "std                 2.524461e+14         4.316935e+17   \n",
       "min                 1.221944e+18         7.867640e+05   \n",
       "25%                 1.223345e+18         7.054162e+07   \n",
       "50%                 1.223391e+18         1.344897e+09   \n",
       "75%                 1.223393e+18         7.302201e+17   \n",
       "max                 1.224119e+18         1.202716e+18   \n",
       "\n",
       "       in_reply_to_user_id_str  contributors  quote_count  reply_count  \\\n",
       "count             1.170000e+02           0.0  2375.000000  2375.000000   \n",
       "mean              2.647967e+17           NaN     0.065684     0.134737   \n",
       "std               4.316935e+17           NaN     1.009173     1.312387   \n",
       "min               7.867640e+05           NaN     0.000000     0.000000   \n",
       "25%               7.054162e+07           NaN     0.000000     0.000000   \n",
       "50%               1.344897e+09           NaN     0.000000     0.000000   \n",
       "75%               7.302201e+17           NaN     0.000000     0.000000   \n",
       "max               1.202716e+18           NaN    37.000000    36.000000   \n",
       "\n",
       "       retweet_count  favorite_count  quoted_status_id  quoted_status_id_str  \n",
       "count    2375.000000     2375.000000      1.890000e+02          1.890000e+02  \n",
       "mean        0.506526        1.038316      1.222812e+18          1.222812e+18  \n",
       "std         6.461853        9.356226      2.511830e+15          2.511830e+15  \n",
       "min         0.000000        0.000000      1.190002e+18          1.190002e+18  \n",
       "25%         0.000000        0.000000      1.222912e+18          1.222912e+18  \n",
       "50%         0.000000        0.000000      1.223229e+18          1.223229e+18  \n",
       "75%         0.000000        0.000000      1.223373e+18          1.223373e+18  \n",
       "max       176.000000      218.000000      1.224101e+18          1.224101e+18  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(df.info())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:11.368052Z",
     "start_time": "2020-06-12T18:26:11.355338Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "test = ast.literal_eval(df.retweeted_status[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:11.388136Z",
     "start_time": "2020-06-12T18:26:11.377390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amazing Timelapse as China Completes First of Two Hospitals in Wuhan within 10 days having 1,000 beds and 1,400 medical staff to treat those infected with the #coronavirus #CoronavirusOutbreak https://t.co/2LH0xhNsHf'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['extended_tweet']['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:11.402238Z",
     "start_time": "2020-06-12T18:26:11.393294Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_full_tweet(series):\n",
    "    series = series.dropna()\n",
    "    full_tweets = []\n",
    "    for value in series:\n",
    "   \n",
    "        converted_value = ast.literal_eval(value)\n",
    "        full_tweet = converted_value['text']\n",
    "        full_tweets.append(full_tweet)\n",
    "    \n",
    "    extended_tweet_df = pd.DataFrame(full_tweets, index=series.index, columns=['full_tweet'])\n",
    "    return extended_tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:12.842503Z",
     "start_time": "2020-06-12T18:26:11.410250Z"
    }
   },
   "outputs": [],
   "source": [
    "extended_tweets = get_full_tweet(df.retweeted_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:12.879013Z",
     "start_time": "2020-06-12T18:26:12.849853Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.join(df, extended_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:12.897359Z",
     "start_time": "2020-06-12T18:26:12.885329Z"
    }
   },
   "outputs": [],
   "source": [
    "df['full_tweet'].fillna(df['text'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessing portion of this project will only include processing text data, so we'll single out that column now. Further preprocessing on the full dataset will be included in the following section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:12.955863Z",
     "start_time": "2020-06-12T18:26:12.915423Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Feb 02 23:59:59 +0000 2020</td>\n",
       "      <td>Amazing Timelapse as China Completes First of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>Bloomberg SCOOP on #coronavirus impact: Chines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>I have become Ill. But no worries, Its just st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>U.S. Hospitals Unprepared For A Quickly Spread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>At this time, the risk to Americans remains lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "1  Sun Feb 02 23:59:59 +0000 2020   \n",
       "2  Sun Feb 02 23:59:58 +0000 2020   \n",
       "3  Sun Feb 02 23:59:58 +0000 2020   \n",
       "4  Sun Feb 02 23:59:58 +0000 2020   \n",
       "5  Sun Feb 02 23:59:58 +0000 2020   \n",
       "\n",
       "                                          full_tweet  \n",
       "1  Amazing Timelapse as China Completes First of ...  \n",
       "2  Bloomberg SCOOP on #coronavirus impact: Chines...  \n",
       "3  I have become Ill. But no worries, Its just st...  \n",
       "4  U.S. Hospitals Unprepared For A Quickly Spread...  \n",
       "5  At this time, the risk to Americans remains lo...  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df = df.loc[:,['created_at','full_tweet']]\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_df['processed_tweet'] = tweet_df.full_tweet.apply(lambda x:x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T19:11:42.833077Z",
     "start_time": "2020-06-16T19:11:42.714803Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bloomberg scoop on #coronavirus impact chinese oil demand said to have dropped by about three million barrels a da httpstcoyvnsuzgfyp']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tweet(tweet):\n",
    "    \n",
    "    '''\n",
    "    This function takes a tweet variable,\n",
    "    removes punctuation and linebreaks,\n",
    "    sets all words to lowercase, and \n",
    "    returns the cleaned tweet as a single\n",
    "    variable list.\n",
    "    '''\n",
    "    \n",
    "    # Grabbing most common punctuation symbols and ellipsis symbol\n",
    "    punctuation_list = list(string.punctuation)+ [\"â€¦\"]\n",
    "    punctuation_list.remove('#')\n",
    "    \n",
    "    cleaned_tweet = []\n",
    "    \n",
    "    for symbol in punctuation_list:\n",
    "        tweet = tweet.replace(symbol, \"\").lower()\n",
    "        tweet = tweet.rstrip()\n",
    "      \n",
    "    cleaned_tweet.append(tweet)\n",
    "    \n",
    "    return cleaned_tweet\n",
    "\n",
    "cleaned_tweet_test = clean_tweet(tweet_df.full_tweet[2])\n",
    "cleaned_tweet_test        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T19:14:19.711855Z",
     "start_time": "2020-06-16T19:14:19.694849Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bloomberg',\n",
       " 'scoop',\n",
       " '#coronavirus',\n",
       " 'impact',\n",
       " 'chinese',\n",
       " 'oil',\n",
       " 'demand',\n",
       " 'said',\n",
       " 'dropped',\n",
       " 'three',\n",
       " 'million',\n",
       " 'barrels',\n",
       " 'da',\n",
       " 'httpstcoyvnsuzgfyp']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(clean_tweet):\n",
    "    \n",
    "    '''\n",
    "    This function takes a cleaned tweet,\n",
    "    joins into one string (if not already),\n",
    "    runs the tweet through NLTK work tokenizer, \n",
    "    removes English stopwords, and returns\n",
    "    the tokenized tweet in list format.\n",
    "    '''\n",
    "    tokenizer = TweetTokenizer()\n",
    "    joined_tweet = ' '.join(clean_tweet)\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    \n",
    "    tokenized_tweet = tokenizer.tokenize(joined_tweet)\n",
    "    tokenized_tweet = [w for w in tokenized_tweet if w not in stopwords_list]\n",
    "    return tokenized_tweet\n",
    "\n",
    "    \n",
    "\n",
    "tokenized_tweet_test = tokenize(cleaned_tweet_test)\n",
    "tokenized_tweet_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T19:15:33.563354Z",
     "start_time": "2020-06-16T19:15:33.548999Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bloomberg scoop on #coronavirus impact chinese oil demand said to have dropped by about three million barrels a da httpstcoyvnsuzgfyp']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_url(tokenized_tweet):\n",
    "    '''\n",
    "    This function takes a tokenized tweet,\n",
    "    applies a regex search for a url,\n",
    "    removes the url, and returns \n",
    "    the tokenized tweet.\n",
    "    '''\n",
    "    url_re = re.compile(r'^https', re.IGNORECASE)\n",
    "    for word in tokenized_tweet:\n",
    "        if url_re.search(word) is not None:\n",
    "            tokenized_tweet.remove(word)\n",
    "        else:\n",
    "            continue\n",
    "    return tokenized_tweet\n",
    "\n",
    "no_url_test = remove_url(cleaned_tweet_test)\n",
    "no_url_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bloomberg scoop on #coronavirus impact chinese oil demand said to have dropped by about three million barrels a da httpstcoyvnsuzgfyp']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_tweet(tweet):\n",
    "    \n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_tweet = [stemmer.stem(word) for word in tweet]\n",
    "    \n",
    "    return stemmed_tweet\n",
    "\n",
    "stem_test = stem_tweet(no_url_test)\n",
    "stem_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Feb 02 23:59:59 +0000 2020</td>\n",
       "      <td>Amazing Timelapse as China Completes First of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>Bloomberg SCOOP on #coronavirus impact: Chines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>I have become Ill. But no worries, Its just st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>U.S. Hospitals Unprepared For A Quickly Spread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>At this time, the risk to Americans remains lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "1  Sun Feb 02 23:59:59 +0000 2020   \n",
       "2  Sun Feb 02 23:59:58 +0000 2020   \n",
       "3  Sun Feb 02 23:59:58 +0000 2020   \n",
       "4  Sun Feb 02 23:59:58 +0000 2020   \n",
       "5  Sun Feb 02 23:59:58 +0000 2020   \n",
       "\n",
       "                                          full_tweet  \n",
       "1  Amazing Timelapse as China Completes First of ...  \n",
       "2  Bloomberg SCOOP on #coronavirus impact: Chines...  \n",
       "3  I have become Ill. But no worries, Its just st...  \n",
       "4  U.S. Hospitals Unprepared For A Quickly Spread...  \n",
       "5  At this time, the risk to Americans remains lo...  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T20:54:28.399504Z",
     "start_time": "2020-06-16T20:54:26.393822Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \n",
    "    cleaned = clean_tweet(tweet)\n",
    "    tokenized = tokenize(cleaned)\n",
    "    stemmed_tweet = stem_tweet(tokenized)\n",
    "    processed_tweet = remove_url(stemmed_tweet)\n",
    "    \n",
    "    return processed_tweet\n",
    "\n",
    "tweet_df['processed_tweets'] = tweet_df['full_tweet'].apply(process_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-16T20:54:30.859385Z",
     "start_time": "2020-06-16T20:54:30.811864Z"
    }
   },
   "outputs": [],
   "source": [
    "tweet_df = tweet_df.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweet_df.processed_tweets:\n",
    "    tweet = \" \".join(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_tweet</th>\n",
       "      <th>processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun Feb 02 23:59:59 +0000 2020</td>\n",
       "      <td>Amazing Timelapse as China Completes First of ...</td>\n",
       "      <td>[amaz, timelaps, china, complet, first, two, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>Bloomberg SCOOP on #coronavirus impact: Chines...</td>\n",
       "      <td>[bloomberg, scoop, #coronavirus, impact, chine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>I have become Ill. But no worries, Its just st...</td>\n",
       "      <td>[becom, ill, worri, stuff, relat, exist, gi, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>U.S. Hospitals Unprepared For A Quickly Spread...</td>\n",
       "      <td>[us, hospit, unprepar, quick, spread, coronavi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>At this time, the risk to Americans remains lo...</td>\n",
       "      <td>[time, risk, american, remain, low, work, keep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Sun Feb 02 23:59:59 +0000 2020   \n",
       "1  Sun Feb 02 23:59:58 +0000 2020   \n",
       "2  Sun Feb 02 23:59:58 +0000 2020   \n",
       "3  Sun Feb 02 23:59:58 +0000 2020   \n",
       "4  Sun Feb 02 23:59:58 +0000 2020   \n",
       "\n",
       "                                          full_tweet  \\\n",
       "0  Amazing Timelapse as China Completes First of ...   \n",
       "1  Bloomberg SCOOP on #coronavirus impact: Chines...   \n",
       "2  I have become Ill. But no worries, Its just st...   \n",
       "3  U.S. Hospitals Unprepared For A Quickly Spread...   \n",
       "4  At this time, the risk to Americans remains lo...   \n",
       "\n",
       "                                    processed_tweets  \n",
       "0  [amaz, timelaps, china, complet, first, two, h...  \n",
       "1  [bloomberg, scoop, #coronavirus, impact, chine...  \n",
       "2  [becom, ill, worri, stuff, relat, exist, gi, i...  \n",
       "3  [us, hospit, unprepar, quick, spread, coronavi...  \n",
       "4  [time, risk, american, remain, low, work, keep...  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-222-02d7fe8e2675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_tweets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mall_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from wordcloud import WordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, list found"
     ]
    }
   ],
   "source": [
    "all_words = ' '.join([text for text in tweet_df['processed_tweets']])\n",
    "all_words\n",
    "# from wordcloud import WordCloud\n",
    "# wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "# plt.axis('off')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:13.028396Z",
     "start_time": "2020-06-12T18:26:13.021185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop geo and contributer data\n",
    "df.drop(['geo', 'coordinates', 'place', 'contributors'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:13.043249Z",
     "start_time": "2020-06-12T18:26:13.033948Z"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['id','id_str','source'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:13.160783Z",
     "start_time": "2020-06-12T18:26:13.047781Z"
    }
   },
   "outputs": [],
   "source": [
    "df.created_at = df.created_at.astype(str)\n",
    "df.created_at = pd.to_datetime(df.created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen below, the earliest date from this set of tweets is January 31, though once my request limits reset, I'll be able to get (hopefully) the rest of the tweets dating back to January 28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T18:26:13.189390Z",
     "start_time": "2020-06-12T18:26:13.167907Z"
    }
   },
   "outputs": [],
   "source": [
    "df.created_at.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
