{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of COVID-19 Tweets: When did the Public Panic Set In? Part 2: Processing Tweets\n",
    "\n",
    "    Notebook by Allison Kelly - allisonkelly42@gmail.com\n",
    "    \n",
    "The following notebook picks up where <a href=\"https://github.com/akelly66/COVID-Tweet-Sentiment/blob/master/tweet-scraping/Twitter-API-Scraping.ipynb\">Part 1: Scraping Tweets</a> left off. In Part 2, I am to process the tweet text to get into a manageable form for modeling. Once the processing functions have been finalized, I will process the training data according to the same rules. You can learn about the training data in Part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:15:18.375351Z",
     "start_time": "2020-08-28T21:15:14.952078Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Generic Imports\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 150) # See more text\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, time\n",
    "\n",
    "# Get JSON\n",
    "import json\n",
    "import ast\n",
    "\n",
    "# Text preprocessing libraries\n",
    "import string\n",
    "import contractions\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import FreqDist\n",
    "from nltk.collocations import *\n",
    "from nltk.collocations import BigramAssocMeasures\n",
    "\n",
    "# Exploratory data analysis libraries\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain Data\n",
    "\n",
    "View method to obtain data <a href=\"https://github.com/akelly66/COVID-Tweet-Sentiment/blob/master/tweet-scraping/COVID-tweets-true.ipynb\">here</a>. <br>\n",
    "<br>The tweet query parameters were as follows:\n",
    "\n",
    "- <b>Keywords: </b> \"coronavirus OR Wuhan virus OR 2019-nCoV OR China flu\"<br>\n",
    "- <b>Date Range: </b> 28 Jan 2020 - 03 Feb 2020<br>\n",
    "- <b>Location:</b> United States of America<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:15:19.831561Z",
     "start_time": "2020-08-28T21:15:19.388076Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>created_at</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>extended_tweet</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>filter_level</th>\n",
       "      <th>...</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status_permalink</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_status</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sun Feb 02 23:59:59 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': [{'screen_name': 'QuestForSense', 'name': 'Atakan Derelioglu, PhD', 'id': 1495052767, 'id_str': '149...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created_at': 'Sun Feb 02 20:44:31 +0000 2020', 'id': 1224071120212627456, 'id_str': '1224071120212627456', 'text': 'Amazing Timelapse as China C...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>RT @QuestForSense: Amazing Timelapse as China Completes First of Two Hospitals in Wuhan within 10 days having 1,000 beds and 1,400 medical‚Ä¶</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 184207003, 'id_str': '184207003', 'name': '‚òÆÔ∏èOpe', 'screen_name': 'The_Ope_', 'location': 'Third rock from the sun', 'url': None, 'descript...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'hashtags': [{'text': 'coronavirus', 'indices': [37, 49]}], 'urls': [], 'user_mentions': [{'screen_name': 'selinawangtv', 'name': 'Selina Wang', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created_at': 'Sun Feb 02 23:44:46 +0000 2020', 'id': 1224116481950011393, 'id_str': '1224116481950011393', 'text': 'Bloomberg SCOOP on #coronavi...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\"&gt;Twitter for iPad&lt;/a&gt;</td>\n",
       "      <td>RT @selinawangtv: Bloomberg SCOOP on #coronavirus impact: Chinese oil demand said to have dropped by about three million barrels a day, or‚Ä¶</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 561036180, 'id_str': '561036180', 'name': 'JJK', 'screen_name': 'jjkenny1', 'location': None, 'url': None, 'description': None, 'translator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': [{'screen_name': 'Marfoogle', 'name': 'MARFOOGLE NEWS (OFFICIAL)', 'id': 961504257051521024, 'id_str...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created_at': 'Sun Feb 02 22:31:43 +0000 2020', 'id': 1224098097468305408, 'id_str': '1224098097468305408', 'text': 'I have become Ill. But no wo...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>RT @Marfoogle: I have become Ill. But no worries, Its just stuff related to my existing G.I. issues. So No coronavirus here. I saw emails c‚Ä¶</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 1211438984229818368, 'id_str': '1211438984229818368', 'name': 'Laura Turner', 'screen_name': 'LauraTu85646722', 'location': 'Utah, USA', 'u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.co/4LkEEVSqqg', 'expanded_url': 'https://www.npr.org/2020/02/02/802087551/u-s-hospitals-unprepared-fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created_at': 'Sun Feb 02 22:26:33 +0000 2020', 'id': 1224096797364088832, 'id_str': '1224096797364088832', 'text': 'U.S. Hospitals Unprepared Fo...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\"&gt;Twitter for iPad&lt;/a&gt;</td>\n",
       "      <td>RT @NPRHealth: U.S. Hospitals Unprepared For A Quickly Spreading Coronavirus https://t.co/4LkEEVSqqg</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 2227143195, 'id_str': '2227143195', 'name': 'Dr. Scott Newton üò∑‚ÜîÔ∏èüò∑', 'screen_name': 'DrScottNewton', 'location': 'USA &amp; Global', 'url': 'ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sun Feb 02 23:59:58 +0000 2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': [{'screen_name': 'PuffDragon11', 'name': 'Puff Dragon', 'id': 1057666719127240704, 'id_str': '105766...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created_at': 'Sat Feb 01 03:05:07 +0000 2020', 'id': 1223442123761975296, 'id_str': '1223442123761975296', 'text': 'Just read the @zerohedge pie...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>RT @PuffDragon11: Just read the @zerohedge piece on the coronavirus. My PhD is in Mol. Bio. No doubt this is an engineered bioweapon and no‚Ä¶</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 1443971138, 'id_str': '1443971138', 'name': 'Josh', 'screen_name': 'JoshAFC', 'location': 'London, England', 'url': 'https://www.arsenal.co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   contributors  coordinates                      created_at  \\\n",
       "0           NaN          NaN  Sun Feb 02 23:59:59 +0000 2020   \n",
       "1           NaN          NaN  Sun Feb 02 23:59:58 +0000 2020   \n",
       "2           NaN          NaN  Sun Feb 02 23:59:58 +0000 2020   \n",
       "3           NaN          NaN  Sun Feb 02 23:59:58 +0000 2020   \n",
       "4           NaN          NaN  Sun Feb 02 23:59:58 +0000 2020   \n",
       "\n",
       "  display_text_range  \\\n",
       "0                NaN   \n",
       "1                NaN   \n",
       "2                NaN   \n",
       "3                NaN   \n",
       "4                NaN   \n",
       "\n",
       "                                                                                                                                                entities  \\\n",
       "0  {'hashtags': [], 'urls': [], 'user_mentions': [{'screen_name': 'QuestForSense', 'name': 'Atakan Derelioglu, PhD', 'id': 1495052767, 'id_str': '149...   \n",
       "1  {'hashtags': [{'text': 'coronavirus', 'indices': [37, 49]}], 'urls': [], 'user_mentions': [{'screen_name': 'selinawangtv', 'name': 'Selina Wang', ...   \n",
       "2  {'hashtags': [], 'urls': [], 'user_mentions': [{'screen_name': 'Marfoogle', 'name': 'MARFOOGLE NEWS (OFFICIAL)', 'id': 961504257051521024, 'id_str...   \n",
       "3  {'hashtags': [], 'urls': [{'url': 'https://t.co/4LkEEVSqqg', 'expanded_url': 'https://www.npr.org/2020/02/02/802087551/u-s-hospitals-unprepared-fo...   \n",
       "4  {'hashtags': [], 'urls': [], 'user_mentions': [{'screen_name': 'PuffDragon11', 'name': 'Puff Dragon', 'id': 1057666719127240704, 'id_str': '105766...   \n",
       "\n",
       "  extended_entities extended_tweet  favorite_count  favorited filter_level  \\\n",
       "0               NaN            NaN               0      False          low   \n",
       "1               NaN            NaN               0      False          low   \n",
       "2               NaN            NaN               0      False          low   \n",
       "3               NaN            NaN               0      False          low   \n",
       "4               NaN            NaN               0      False          low   \n",
       "\n",
       "   ...  quoted_status_id_str  quoted_status_permalink  reply_count  \\\n",
       "0  ...                   NaN                      NaN            0   \n",
       "1  ...                   NaN                      NaN            0   \n",
       "2  ...                   NaN                      NaN            0   \n",
       "3  ...                   NaN                      NaN            0   \n",
       "4  ...                   NaN                      NaN            0   \n",
       "\n",
       "  retweet_count  retweeted  \\\n",
       "0             0      False   \n",
       "1             0      False   \n",
       "2             0      False   \n",
       "3             0      False   \n",
       "4             0      False   \n",
       "\n",
       "                                                                                                                                        retweeted_status  \\\n",
       "0  {'created_at': 'Sun Feb 02 20:44:31 +0000 2020', 'id': 1224071120212627456, 'id_str': '1224071120212627456', 'text': 'Amazing Timelapse as China C...   \n",
       "1  {'created_at': 'Sun Feb 02 23:44:46 +0000 2020', 'id': 1224116481950011393, 'id_str': '1224116481950011393', 'text': 'Bloomberg SCOOP on #coronavi...   \n",
       "2  {'created_at': 'Sun Feb 02 22:31:43 +0000 2020', 'id': 1224098097468305408, 'id_str': '1224098097468305408', 'text': 'I have become Ill. But no wo...   \n",
       "3  {'created_at': 'Sun Feb 02 22:26:33 +0000 2020', 'id': 1224096797364088832, 'id_str': '1224096797364088832', 'text': 'U.S. Hospitals Unprepared Fo...   \n",
       "4  {'created_at': 'Sat Feb 01 03:05:07 +0000 2020', 'id': 1223442123761975296, 'id_str': '1223442123761975296', 'text': 'Just read the @zerohedge pie...   \n",
       "\n",
       "                                                                                 source  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "1     <a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>   \n",
       "2  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "3     <a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>   \n",
       "4  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "\n",
       "                                                                                                                                           text  \\\n",
       "0   RT @QuestForSense: Amazing Timelapse as China Completes First of Two Hospitals in Wuhan within 10 days having 1,000 beds and 1,400 medical‚Ä¶   \n",
       "1   RT @selinawangtv: Bloomberg SCOOP on #coronavirus impact: Chinese oil demand said to have dropped by about three million barrels a day, or‚Ä¶   \n",
       "2  RT @Marfoogle: I have become Ill. But no worries, Its just stuff related to my existing G.I. issues. So No coronavirus here. I saw emails c‚Ä¶   \n",
       "3                                          RT @NPRHealth: U.S. Hospitals Unprepared For A Quickly Spreading Coronavirus https://t.co/4LkEEVSqqg   \n",
       "4  RT @PuffDragon11: Just read the @zerohedge piece on the coronavirus. My PhD is in Mol. Bio. No doubt this is an engineered bioweapon and no‚Ä¶   \n",
       "\n",
       "   truncated  \\\n",
       "0      False   \n",
       "1      False   \n",
       "2      False   \n",
       "3      False   \n",
       "4      False   \n",
       "\n",
       "                                                                                                                                                    user  \n",
       "0  {'id': 184207003, 'id_str': '184207003', 'name': '‚òÆÔ∏èOpe', 'screen_name': 'The_Ope_', 'location': 'Third rock from the sun', 'url': None, 'descript...  \n",
       "1  {'id': 561036180, 'id_str': '561036180', 'name': 'JJK', 'screen_name': 'jjkenny1', 'location': None, 'url': None, 'description': None, 'translator...  \n",
       "2  {'id': 1211438984229818368, 'id_str': '1211438984229818368', 'name': 'Laura Turner', 'screen_name': 'LauraTu85646722', 'location': 'Utah, USA', 'u...  \n",
       "3  {'id': 2227143195, 'id_str': '2227143195', 'name': 'Dr. Scott Newton üò∑‚ÜîÔ∏èüò∑', 'screen_name': 'DrScottNewton', 'location': 'USA & Global', 'url': 'ht...  \n",
       "4  {'id': 1443971138, 'id_str': '1443971138', 'name': 'Josh', 'screen_name': 'JoshAFC', 'location': 'London, England', 'url': 'https://www.arsenal.co...  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"expanded_query_tweets.csv\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df.query(\"lang == 'en'\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:15:21.772962Z",
     "start_time": "2020-08-28T21:15:21.649597Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2996\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2996 entries, 0 to 2999\n",
      "Data columns (total 36 columns):\n",
      "contributors                 0 non-null float64\n",
      "coordinates                  0 non-null float64\n",
      "created_at                   2996 non-null object\n",
      "display_text_range           228 non-null object\n",
      "entities                     2996 non-null object\n",
      "extended_entities            244 non-null object\n",
      "extended_tweet               234 non-null object\n",
      "favorite_count               2996 non-null int64\n",
      "favorited                    2996 non-null bool\n",
      "filter_level                 2996 non-null object\n",
      "geo                          0 non-null float64\n",
      "id                           2996 non-null int64\n",
      "id_str                       2996 non-null int64\n",
      "in_reply_to_screen_name      141 non-null object\n",
      "in_reply_to_status_id        133 non-null float64\n",
      "in_reply_to_status_id_str    133 non-null float64\n",
      "in_reply_to_user_id          146 non-null float64\n",
      "in_reply_to_user_id_str      146 non-null float64\n",
      "is_quote_status              2996 non-null bool\n",
      "lang                         2996 non-null object\n",
      "matching_rules               2996 non-null object\n",
      "place                        13 non-null object\n",
      "possibly_sensitive           862 non-null object\n",
      "quote_count                  2996 non-null int64\n",
      "quoted_status                201 non-null object\n",
      "quoted_status_id             226 non-null float64\n",
      "quoted_status_id_str         226 non-null float64\n",
      "quoted_status_permalink      201 non-null object\n",
      "reply_count                  2996 non-null int64\n",
      "retweet_count                2996 non-null int64\n",
      "retweeted                    2996 non-null bool\n",
      "retweeted_status             2423 non-null object\n",
      "source                       2996 non-null object\n",
      "text                         2996 non-null object\n",
      "truncated                    2996 non-null bool\n",
      "user                         2996 non-null object\n",
      "dtypes: bool(4), float64(9), int64(6), object(17)\n",
      "memory usage: 784.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contributors</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>geo</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_status_id_str</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>in_reply_to_user_id_str</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2996.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.996000e+03</td>\n",
       "      <td>2.996000e+03</td>\n",
       "      <td>1.330000e+02</td>\n",
       "      <td>1.330000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>1.460000e+02</td>\n",
       "      <td>2996.000000</td>\n",
       "      <td>2.260000e+02</td>\n",
       "      <td>2.260000e+02</td>\n",
       "      <td>2996.000000</td>\n",
       "      <td>2996.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.985981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.223419e+18</td>\n",
       "      <td>1.223419e+18</td>\n",
       "      <td>1.223356e+18</td>\n",
       "      <td>1.223356e+18</td>\n",
       "      <td>2.864927e+17</td>\n",
       "      <td>2.864927e+17</td>\n",
       "      <td>0.062083</td>\n",
       "      <td>1.222852e+18</td>\n",
       "      <td>1.222852e+18</td>\n",
       "      <td>0.164553</td>\n",
       "      <td>0.622497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.995987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.303859e+14</td>\n",
       "      <td>1.303859e+14</td>\n",
       "      <td>2.380334e+14</td>\n",
       "      <td>2.380334e+14</td>\n",
       "      <td>4.388216e+17</td>\n",
       "      <td>4.388216e+17</td>\n",
       "      <td>0.856762</td>\n",
       "      <td>2.313826e+15</td>\n",
       "      <td>2.313826e+15</td>\n",
       "      <td>1.686030</td>\n",
       "      <td>9.376703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.223394e+18</td>\n",
       "      <td>1.223394e+18</td>\n",
       "      <td>1.221944e+18</td>\n",
       "      <td>1.221944e+18</td>\n",
       "      <td>7.867640e+05</td>\n",
       "      <td>7.867640e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.190002e+18</td>\n",
       "      <td>1.190002e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.223394e+18</td>\n",
       "      <td>1.223394e+18</td>\n",
       "      <td>1.223346e+18</td>\n",
       "      <td>1.223346e+18</td>\n",
       "      <td>6.412300e+07</td>\n",
       "      <td>6.412300e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.222953e+18</td>\n",
       "      <td>1.222953e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.223395e+18</td>\n",
       "      <td>1.223395e+18</td>\n",
       "      <td>1.223389e+18</td>\n",
       "      <td>1.223389e+18</td>\n",
       "      <td>1.342405e+09</td>\n",
       "      <td>1.342405e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223240e+18</td>\n",
       "      <td>1.223240e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.223395e+18</td>\n",
       "      <td>1.223395e+18</td>\n",
       "      <td>1.223393e+18</td>\n",
       "      <td>1.223393e+18</td>\n",
       "      <td>7.661313e+17</td>\n",
       "      <td>7.661313e+17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223373e+18</td>\n",
       "      <td>1.223373e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.224120e+18</td>\n",
       "      <td>1.224120e+18</td>\n",
       "      <td>1.224119e+18</td>\n",
       "      <td>1.224119e+18</td>\n",
       "      <td>1.202716e+18</td>\n",
       "      <td>1.202716e+18</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.224101e+18</td>\n",
       "      <td>1.224101e+18</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>393.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       contributors  coordinates  favorite_count  geo            id  \\\n",
       "count           0.0          0.0     2996.000000  0.0  2.996000e+03   \n",
       "mean            NaN          NaN        1.985981  NaN  1.223419e+18   \n",
       "std             NaN          NaN       40.995987  NaN  1.303859e+14   \n",
       "min             NaN          NaN        0.000000  NaN  1.223394e+18   \n",
       "25%             NaN          NaN        0.000000  NaN  1.223394e+18   \n",
       "50%             NaN          NaN        0.000000  NaN  1.223395e+18   \n",
       "75%             NaN          NaN        0.000000  NaN  1.223395e+18   \n",
       "max             NaN          NaN     2013.000000  NaN  1.224120e+18   \n",
       "\n",
       "             id_str  in_reply_to_status_id  in_reply_to_status_id_str  \\\n",
       "count  2.996000e+03           1.330000e+02               1.330000e+02   \n",
       "mean   1.223419e+18           1.223356e+18               1.223356e+18   \n",
       "std    1.303859e+14           2.380334e+14               2.380334e+14   \n",
       "min    1.223394e+18           1.221944e+18               1.221944e+18   \n",
       "25%    1.223394e+18           1.223346e+18               1.223346e+18   \n",
       "50%    1.223395e+18           1.223389e+18               1.223389e+18   \n",
       "75%    1.223395e+18           1.223393e+18               1.223393e+18   \n",
       "max    1.224120e+18           1.224119e+18               1.224119e+18   \n",
       "\n",
       "       in_reply_to_user_id  in_reply_to_user_id_str  quote_count  \\\n",
       "count         1.460000e+02             1.460000e+02  2996.000000   \n",
       "mean          2.864927e+17             2.864927e+17     0.062083   \n",
       "std           4.388216e+17             4.388216e+17     0.856762   \n",
       "min           7.867640e+05             7.867640e+05     0.000000   \n",
       "25%           6.412300e+07             6.412300e+07     0.000000   \n",
       "50%           1.342405e+09             1.342405e+09     0.000000   \n",
       "75%           7.661313e+17             7.661313e+17     0.000000   \n",
       "max           1.202716e+18             1.202716e+18    29.000000   \n",
       "\n",
       "       quoted_status_id  quoted_status_id_str  reply_count  retweet_count  \n",
       "count      2.260000e+02          2.260000e+02  2996.000000    2996.000000  \n",
       "mean       1.222852e+18          1.222852e+18     0.164553       0.622497  \n",
       "std        2.313826e+15          2.313826e+15     1.686030       9.376703  \n",
       "min        1.190002e+18          1.190002e+18     0.000000       0.000000  \n",
       "25%        1.222953e+18          1.222953e+18     0.000000       0.000000  \n",
       "50%        1.223240e+18          1.223240e+18     0.000000       0.000000  \n",
       "75%        1.223373e+18          1.223373e+18     0.000000       0.000000  \n",
       "max        1.224101e+18          1.224101e+18    48.000000     393.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(df.info())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the tweets are truncated due to being retweets. The full, original tweet can be found in the retweeted_status column. The responses from the Twitter API are nested JSON objects, however when I converted them into a dataframe, the nested JSON objects became dictionary-like strings. The following cells will use abstract syntax trees to convert the string to a dictionary (though I'm really not sure why or how it works!) and pull the full text of the original tweet. I believe it's important to the sentiment analysis to interpret the original content as supported by the profile doing the retweeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:15:26.252734Z",
     "start_time": "2020-08-28T21:15:24.319848Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(row):\n",
    "    '''\n",
    "    This function, when applied to\n",
    "    the series containing \n",
    "    dictionary-like strings will \n",
    "    convert each instance to\n",
    "    actual dictionaries and return\n",
    "    the dictionary.\n",
    "    '''\n",
    "    \n",
    "    row = ast.literal_eval(row) \n",
    "    return row\n",
    "\n",
    "# Saving dictionaries in new column\n",
    "df['expanded'] = df.retweeted_status.dropna().apply(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:15:31.418584Z",
     "start_time": "2020-08-28T21:15:26.257442Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating features from dictionary keys in new dataframe\n",
    "expanded_df = df['expanded'].apply(pd.Series)\n",
    "\n",
    "# Again, unnesting another dictionary to get to the full_text column\n",
    "expanded_df = expanded_df.extended_tweet.apply(pd.Series)\n",
    "\n",
    "# Dropping rows corresponding to original tweets (not retweeted text)\n",
    "expanded_df = expanded_df.full_text.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:15:31.449404Z",
     "start_time": "2020-08-28T21:15:31.423822Z"
    }
   },
   "outputs": [],
   "source": [
    "# Joining with original dataframe\n",
    "df = pd.DataFrame.join(df, expanded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:15:32.341455Z",
     "start_time": "2020-08-28T21:15:32.335214Z"
    }
   },
   "outputs": [],
   "source": [
    "# Swapping NaNs for original tweets in the full text column\n",
    "df['full_text'].fillna(df['text'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Tweet Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the entirety of the dataset is a treasure trove of information, I've singled out just the text portion to process for the sentiment analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:20:07.630592Z",
     "start_time": "2020-08-28T21:20:07.618438Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Amazing Timelapse as China Completes First of Two Hospitals in Wuhan within 10 days having 1,000 beds and 1,400 medical staff to treat those infec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Bloomberg SCOOP on #coronavirus impact: Chinese oil demand said to have dropped by about three million barrels a day, or 20% of total consumption....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I have become Ill. But no worries, Its just stuff related to my existing G.I. issues. So No coronavirus here. I saw emails concerning my visit to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>RT @NPRHealth: U.S. Hospitals Unprepared For A Quickly Spreading Coronavirus https://t.co/4LkEEVSqqg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just read the @zerohedge piece on the coronavirus. My PhD is in Mol. Bio. No doubt this is an engineered bioweapon and not natural. Statistically ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               full_text\n",
       "0  Amazing Timelapse as China Completes First of Two Hospitals in Wuhan within 10 days having 1,000 beds and 1,400 medical staff to treat those infec...\n",
       "1  Bloomberg SCOOP on #coronavirus impact: Chinese oil demand said to have dropped by about three million barrels a day, or 20% of total consumption....\n",
       "2  I have become Ill. But no worries, Its just stuff related to my existing G.I. issues. So No coronavirus here. I saw emails concerning my visit to ...\n",
       "3                                                   RT @NPRHealth: U.S. Hospitals Unprepared For A Quickly Spreading Coronavirus https://t.co/4LkEEVSqqg\n",
       "4  Just read the @zerohedge piece on the coronavirus. My PhD is in Mol. Bio. No doubt this is an engineered bioweapon and not natural. Statistically ..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df = df.loc[:,['full_text']]\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T22:33:47.720065Z",
     "start_time": "2020-08-28T22:33:47.692318Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_url_and_RT(row):\n",
    "    '''\n",
    "    This function takes each tweet\n",
    "    and removes the urls and retweet\n",
    "    indicator from them.\n",
    "    '''\n",
    "    \n",
    "    row = re.sub('https://[A-Za-z0-9./]+',\"\",row)\n",
    "    row = re.sub('http://[A-Za-z0-9./]+',\"\",row)\n",
    "    row = re.sub('^RT',\"\", row)\n",
    "    return row\n",
    "\n",
    "tweet_df.full_text = tweet_df.full_text.apply(remove_url_and_RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:23:08.385339Z",
     "start_time": "2020-08-28T21:23:08.371039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Amazing Timelapse as China Completes First of Two Hospitals in Wuhan within 10 days having 1,000 beds and 1,400 medical staff to treat those infec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Bloomberg SCOOP on #coronavirus impact: Chinese oil demand said to have dropped by about three million barrels a day, or 20% of total consumption....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I have become Ill. But no worries, Its just stuff related to my existing G.I. issues. So No coronavirus here. I saw emails concerning my visit to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@NPRHealth: U.S. Hospitals Unprepared For A Quickly Spreading Coronavirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just read the @zerohedge piece on the coronavirus. My PhD is in Mol. Bio. No doubt this is an engineered bioweapon and not natural. Statistically ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               full_text\n",
       "0  Amazing Timelapse as China Completes First of Two Hospitals in Wuhan within 10 days having 1,000 beds and 1,400 medical staff to treat those infec...\n",
       "1  Bloomberg SCOOP on #coronavirus impact: Chinese oil demand said to have dropped by about three million barrels a day, or 20% of total consumption....\n",
       "2  I have become Ill. But no worries, Its just stuff related to my existing G.I. issues. So No coronavirus here. I saw emails concerning my visit to ...\n",
       "3                                                                             @NPRHealth: U.S. Hospitals Unprepared For A Quickly Spreading Coronavirus \n",
       "4  Just read the @zerohedge piece on the coronavirus. My PhD is in Mol. Bio. No doubt this is an engineered bioweapon and not natural. Statistically ..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:23:17.263306Z",
     "start_time": "2020-08-28T21:23:17.250720Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bloomberg scoop on #coronavirus impact chinese oil demand said to have dropped by about three million barrels a day or 20 of total consumption china is the worlds largest oil importer w outsized impact on the global energy mkt business quicktake']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tweet(tweet):\n",
    "    \n",
    "    '''\n",
    "    This function takes a tweet variable,\n",
    "    removes punctuation and linebreaks,\n",
    "    sets all words to lowercase, and \n",
    "    returns the cleaned tweet as a single\n",
    "    variable list.\n",
    "    '''\n",
    "    \n",
    "    # Grabbing most common punctuation symbols and ellipsis symbol\n",
    "    punctuation_list = list(string.punctuation)+ [\"‚Ä¶\"] + ['‚Äô']\n",
    "    punctuation_list.remove('#')\n",
    "    \n",
    "    \n",
    "    cleaned_tweet = []\n",
    "    \n",
    "    for symbol in punctuation_list:\n",
    "        \n",
    "        tweet = tweet.replace(symbol, \"\").lower()\n",
    "        \n",
    "        # Removing trailing characters\n",
    "        tweet = tweet.rstrip()\n",
    "        \n",
    "        # Cleaning non-ASCII characters\n",
    "        tweet = re.sub(\"([^\\x00-\\x7F])+\",\"\",tweet)\n",
    "      \n",
    "    cleaned_tweet.append(tweet)\n",
    "    \n",
    "    return cleaned_tweet\n",
    "\n",
    "cleaned_tweet_test = clean_tweet(tweet_df.full_text[1])\n",
    "cleaned_tweet_test        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:23:18.294227Z",
     "start_time": "2020-08-28T21:23:18.274025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bloomberg',\n",
       " 'scoop',\n",
       " '#coronavirus',\n",
       " 'impact',\n",
       " 'chinese',\n",
       " 'oil',\n",
       " 'demand',\n",
       " 'said',\n",
       " 'dropped',\n",
       " 'three',\n",
       " 'million',\n",
       " 'barrels',\n",
       " 'day',\n",
       " 'total',\n",
       " 'consumption',\n",
       " 'china',\n",
       " 'worlds',\n",
       " 'largest',\n",
       " 'oil',\n",
       " 'importer',\n",
       " 'w',\n",
       " 'outsized',\n",
       " 'impact',\n",
       " 'global',\n",
       " 'energy',\n",
       " 'mkt',\n",
       " 'business',\n",
       " 'quicktake']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(clean_tweet):\n",
    "    \n",
    "    '''\n",
    "    This function takes a cleaned tweet,\n",
    "    joins into one string (if not already),\n",
    "    runs the tweet through NLTK work tokenizer, \n",
    "    removes English stopwords, replaces \"us\"\n",
    "    with \"usa,\" removes numbers and returns\n",
    "    the tokenized tweet in list format.\n",
    "    '''\n",
    "    \n",
    "    joined_tweet = ' '.join(clean_tweet)\n",
    "    stopwords_list = stopwords.words('english')\n",
    "    \n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokenized_tweet = tokenizer.tokenize(joined_tweet)\n",
    "    # Removing stopwords\n",
    "    tokenized_tweet = [word for word in tokenized_tweet if word not in stopwords_list]\n",
    "    \n",
    "    # Subbing 'usa' for 'us'\n",
    "    tokenized_tweet = ['usa' if word == 'us' else word for word in tokenized_tweet]\n",
    "    \n",
    "    # Removing numbers\n",
    "    tokenized_tweet = [word for word in tokenized_tweet if not word.isnumeric()]\n",
    "    \n",
    "    return tokenized_tweet\n",
    "\n",
    "    \n",
    "\n",
    "tokenized_tweet_test = tokenize(cleaned_tweet_test)\n",
    "tokenized_tweet_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:23:22.188301Z",
     "start_time": "2020-08-28T21:23:22.181825Z"
    }
   },
   "outputs": [],
   "source": [
    "def lem_tweet(tweet):\n",
    "    '''\n",
    "    This function takes a tweet in\n",
    "    the form of a tokenized\n",
    "    word list and lemmatizes it.\n",
    "    '''\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    lemmed_tweet = [lemmatizer.lemmatize(word) for word in tweet]\n",
    "    \n",
    "    return lemmed_tweet\n",
    "\n",
    "lemmed_tweet_test = lem_tweet(tokenized_tweet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:23:23.381490Z",
     "start_time": "2020-08-28T21:23:23.369947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bloomberg',\n",
       " 'scoop',\n",
       " '#coronavirus',\n",
       " 'impact',\n",
       " 'chinese',\n",
       " 'oil',\n",
       " 'demand',\n",
       " 'said',\n",
       " 'dropped',\n",
       " 'three',\n",
       " 'million',\n",
       " 'barrel',\n",
       " 'day',\n",
       " 'total',\n",
       " 'consumption',\n",
       " 'china',\n",
       " 'world',\n",
       " 'largest',\n",
       " 'oil',\n",
       " 'importer',\n",
       " 'w',\n",
       " 'outsized',\n",
       " 'impact',\n",
       " 'global',\n",
       " 'energy',\n",
       " 'mkt',\n",
       " 'business',\n",
       " 'quicktake']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmed_tweet_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:23:24.991855Z",
     "start_time": "2020-08-28T21:23:24.981676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bloomberg',\n",
       " 'scoop',\n",
       " '#coronavirus',\n",
       " 'impact',\n",
       " 'chines',\n",
       " 'oil',\n",
       " 'demand',\n",
       " 'said',\n",
       " 'drop',\n",
       " 'three',\n",
       " 'million',\n",
       " 'barrel',\n",
       " 'day',\n",
       " 'total',\n",
       " 'consumpt',\n",
       " 'china',\n",
       " 'world',\n",
       " 'largest',\n",
       " 'oil',\n",
       " 'import',\n",
       " 'w',\n",
       " 'outsiz',\n",
       " 'impact',\n",
       " 'global',\n",
       " 'energi',\n",
       " 'mkt',\n",
       " 'busi',\n",
       " 'quicktak']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_tweet(tweet):\n",
    "    \n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_tweet = [stemmer.stem(word) for word in tweet]\n",
    "    \n",
    "    return stemmed_tweet\n",
    "\n",
    "stem_test = stem_tweet(lemmed_tweet_test)\n",
    "stem_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T22:34:11.040451Z",
     "start_time": "2020-08-28T22:34:11.033443Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    '''\n",
    "    This function takes an original \n",
    "    tweet, cleans, tokenizes, \n",
    "    and lemmatizes the tweet.\n",
    "    '''\n",
    "    \n",
    "    cleaned = clean_tweet(tweet)\n",
    "    tokenized = tokenize(cleaned)\n",
    "#     stemmed_tweet = stem_tweet(tokenized)\n",
    "    lemmed_tweet = lem_tweet(tokenized)\n",
    "    \n",
    "    return lemmed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:25:43.358514Z",
     "start_time": "2020-08-28T21:25:40.348863Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Amazing Timelapse as China Completes First of Two Hospitals in Wuhan within 10 days having 1,000 beds and 1,400 medical staff to treat those infec...</td>\n",
       "      <td>[amazing, timelapse, china, completes, first, two, hospital, wuhan, within, day, bed, medical, staff, treat, infected, #coronavirus, #coronaviruso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Bloomberg SCOOP on #coronavirus impact: Chinese oil demand said to have dropped by about three million barrels a day, or 20% of total consumption....</td>\n",
       "      <td>[bloomberg, scoop, #coronavirus, impact, chinese, oil, demand, said, dropped, three, million, barrel, day, total, consumption, china, world, large...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I have become Ill. But no worries, Its just stuff related to my existing G.I. issues. So No coronavirus here. I saw emails concerning my visit to ...</td>\n",
       "      <td>[become, ill, worry, stuff, related, existing, gi, issue, coronavirus, saw, email, concerning, visit, provedence, hospitalhome, first, usa, case, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@NPRHealth: U.S. Hospitals Unprepared For A Quickly Spreading Coronavirus</td>\n",
       "      <td>[nprhealth, usa, hospital, unprepared, quickly, spreading, coronavirus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Just read the @zerohedge piece on the coronavirus. My PhD is in Mol. Bio. No doubt this is an engineered bioweapon and not natural. Statistically ...</td>\n",
       "      <td>[read, zerohedge, piece, coronavirus, phd, mol, bio, doubt, engineered, bioweapon, natural, statistically, improbably, segment, map, completely, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               full_text  \\\n",
       "0  Amazing Timelapse as China Completes First of Two Hospitals in Wuhan within 10 days having 1,000 beds and 1,400 medical staff to treat those infec...   \n",
       "1  Bloomberg SCOOP on #coronavirus impact: Chinese oil demand said to have dropped by about three million barrels a day, or 20% of total consumption....   \n",
       "2  I have become Ill. But no worries, Its just stuff related to my existing G.I. issues. So No coronavirus here. I saw emails concerning my visit to ...   \n",
       "3                                                                             @NPRHealth: U.S. Hospitals Unprepared For A Quickly Spreading Coronavirus    \n",
       "4  Just read the @zerohedge piece on the coronavirus. My PhD is in Mol. Bio. No doubt this is an engineered bioweapon and not natural. Statistically ...   \n",
       "\n",
       "                                                                                                                                        processed_tweets  \n",
       "0  [amazing, timelapse, china, completes, first, two, hospital, wuhan, within, day, bed, medical, staff, treat, infected, #coronavirus, #coronaviruso...  \n",
       "1  [bloomberg, scoop, #coronavirus, impact, chinese, oil, demand, said, dropped, three, million, barrel, day, total, consumption, china, world, large...  \n",
       "2  [become, ill, worry, stuff, related, existing, gi, issue, coronavirus, saw, email, concerning, visit, provedence, hospitalhome, first, usa, case, ...  \n",
       "3                                                                                [nprhealth, usa, hospital, unprepared, quickly, spreading, coronavirus]  \n",
       "4  [read, zerohedge, piece, coronavirus, phd, mol, bio, doubt, engineered, bioweapon, natural, statistically, improbably, segment, map, completely, d...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing COVID tweets\n",
    "tweet_df['processed_tweets'] = tweet_df['full_text'].apply(process_tweet)\n",
    "\n",
    "# Resetting index\n",
    "tweet_df = tweet_df.reset_index().drop('index',axis=1)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good! Below, I'll process the training tweets. The dataset will be explored in Part 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T21:29:42.735307Z",
     "start_time": "2020-08-28T21:29:33.999648Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Allie/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>twitter_handle</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "      <td>['switchfoot', 'httptwitpiccom', '2y1zl', 'awww', 'thats', 'bummer', 'shoulda', 'got', 'david', 'carr', 'third', 'day']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "      <td>['upset', 'cant', 'update', 'facebook', 'texting', 'might', 'cry', 'result', 'school', 'today', 'also', 'blah']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "      <td>['kenichan', 'dived', 'many', 'time', 'ball', 'managed', 'save', 'rest', 'go', 'bound']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>['whole', 'body', 'feel', 'itchy', 'like', 'fire']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "      <td>['nationwideclass', 'behaving', 'im', 'mad', 'cant', 'see']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity    tweet_id                          date     query  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "    twitter_handle  \\\n",
       "0  _TheSpecialOne_   \n",
       "1    scotthamilton   \n",
       "2         mattycus   \n",
       "3          ElleCTF   \n",
       "4           Karoli   \n",
       "\n",
       "                                                                                                                 tweet  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D   \n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!   \n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds   \n",
       "3                                                                      my whole body feels itchy and like its on fire    \n",
       "4      @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.    \n",
       "\n",
       "                                                                                                          processed_tweets  \n",
       "0  ['switchfoot', 'httptwitpiccom', '2y1zl', 'awww', 'thats', 'bummer', 'shoulda', 'got', 'david', 'carr', 'third', 'day']  \n",
       "1          ['upset', 'cant', 'update', 'facebook', 'texting', 'might', 'cry', 'result', 'school', 'today', 'also', 'blah']  \n",
       "2                                  ['kenichan', 'dived', 'many', 'time', 'ball', 'managed', 'save', 'rest', 'go', 'bound']  \n",
       "3                                                                       ['whole', 'body', 'feel', 'itchy', 'like', 'fire']  \n",
       "4                                                              ['nationwideclass', 'behaving', 'im', 'mad', 'cant', 'see']  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.read_csv('training_tweets.csv',index_col=0)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T22:29:50.312419Z",
     "start_time": "2020-08-28T22:29:50.138510Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity  \\\n",
       "0         0   \n",
       "1         0   \n",
       "2         0   \n",
       "3         0   \n",
       "4         0   \n",
       "\n",
       "                                                                                                                 tweet  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!  \n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds  \n",
       "3                                                                      my whole body feels itchy and like its on fire   \n",
       "4      @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.   "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = training_set.loc[:,[\"polarity\",\"tweet\"]]\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T23:29:55.392724Z",
     "start_time": "2020-08-28T22:34:19.023143Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "      <th>processed_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "      <td>[switchfoot, httptwitpiccom, 2y1zl, awww, thats, bummer, shoulda, got, david, carr, third, day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "      <td>[upset, cant, update, facebook, texting, might, cry, result, school, today, also, blah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "      <td>[kenichan, dived, many, time, ball, managed, save, rest, go, bound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[whole, body, feel, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "      <td>[nationwideclass, behaving, im, mad, cant, see]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity  \\\n",
       "0         0   \n",
       "1         0   \n",
       "2         0   \n",
       "3         0   \n",
       "4         0   \n",
       "\n",
       "                                                                                                                 tweet  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D   \n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!   \n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds   \n",
       "3                                                                      my whole body feels itchy and like its on fire    \n",
       "4      @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.    \n",
       "\n",
       "                                                                                   processed_train  \n",
       "0  [switchfoot, httptwitpiccom, 2y1zl, awww, thats, bummer, shoulda, got, david, carr, third, day]  \n",
       "1          [upset, cant, update, facebook, texting, might, cry, result, school, today, also, blah]  \n",
       "2                              [kenichan, dived, many, time, ball, managed, save, rest, go, bound]  \n",
       "3                                                           [whole, body, feel, itchy, like, fire]  \n",
       "4                                                  [nationwideclass, behaving, im, mad, cant, see]  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing training tweets\n",
    "training_set['processed_train'] = training_set['tweet'].apply(process_tweet)\n",
    "\n",
    "# Resetting index\n",
    "training_set = training_set.reset_index().drop('index',axis=1)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectorization\n",
    "\n",
    "This portion will be moved to another notebook. Please ignore for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv('processed_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = tweet_df.processed_tweets.apply(('').join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected...\n",
       "1       ['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'con...\n",
       "2       ['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hos...\n",
       "3                                                                       ['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']\n",
       "4       ['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', '...\n",
       "                                                                                ...                                                                          \n",
       "2991    ['due', 'threat', 'novel', 'coronavirus', 'statedept', 'recently', 'adjusted', 'travel', 'advisory', '#china', 'level', 'meaning', 'individual', '...\n",
       "2992    ['al', 'qaeda', 'leader', 'killed', 'really', 'love', 'thisin', 'midst', 'impeachment', 'fear', 'coronavirus', 'thing', 'dominating', 'headline', ...\n",
       "2993                                                    ['globeandmail', 'usa', 'declares', 'emergency', 'new', 'entry', 'restriction', 'due', 'coronavirus']\n",
       "2994                ['prayingmedic', 'indictment', 'unsealed', 'harvard', 'professor', 'developed', 'wuhan', 'virus', 'sold', 'chinese', 'million', 'dollar']\n",
       "2995                                                                  ['kurtschlichter', 'stop', 'eating', 'bat', 'coronavirus', 'could', 'trump', 'katrina']\n",
       "Name: processed_tweets, Length: 2996, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(tweet_list)\n",
    "dense_matrix = tfidf_matrix.todense()\n",
    "dense_list = dense_matrix.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(dense_list, columns = vectorizer.get_feature_names(), index=tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaggghhhhh</th>\n",
       "      <th>aampe</th>\n",
       "      <th>aasma</th>\n",
       "      <th>abbvie</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcchicago</th>\n",
       "      <th>abcnews</th>\n",
       "      <th>abcnewsbayarea</th>\n",
       "      <th>abdirashidm</th>\n",
       "      <th>...</th>\n",
       "      <th>zhengli</th>\n",
       "      <th>zhou</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zimbabwean</th>\n",
       "      <th>zls</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoonotic</th>\n",
       "      <th>zorrillaalex</th>\n",
       "      <th>zxrnoh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>processed_tweets</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected', '#coronavirus', '#coronavirusoutbreak']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'consumption', 'china', 'world', 'largest', 'oil', 'importer', 'w', 'outsized', 'impact', 'global', 'energy', 'mkt', 'business', 'quicktake']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hospitalhome', 'first', 'usa', 'case', 'contact', 'anyone', 'kept', 'distance', 'hospital']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 'segment', 'map', 'completely', 'different', 'virus', 'hiv', 'conservation']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 5740 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                         aa  \\\n",
       "processed_tweets                                                                                                                                              \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...  0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...  0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...  0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                   0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...  0.0   \n",
       "\n",
       "                                                                                                                                                        aaaaggghhhhh  \\\n",
       "processed_tweets                                                                                                                                                       \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...           0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...           0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...           0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                            0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...           0.0   \n",
       "\n",
       "                                                                                                                                                        aampe  \\\n",
       "processed_tweets                                                                                                                                                \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...    0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...    0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...    0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                     0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...    0.0   \n",
       "\n",
       "                                                                                                                                                        aasma  \\\n",
       "processed_tweets                                                                                                                                                \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...    0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...    0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...    0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                     0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...    0.0   \n",
       "\n",
       "                                                                                                                                                        abbvie  \\\n",
       "processed_tweets                                                                                                                                                 \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...     0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...     0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...     0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                      0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...     0.0   \n",
       "\n",
       "                                                                                                                                                        abc  \\\n",
       "processed_tweets                                                                                                                                              \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...  0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...  0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...  0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                   0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...  0.0   \n",
       "\n",
       "                                                                                                                                                        abcchicago  \\\n",
       "processed_tweets                                                                                                                                                     \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...         0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...         0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...         0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                          0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...         0.0   \n",
       "\n",
       "                                                                                                                                                        abcnews  \\\n",
       "processed_tweets                                                                                                                                                  \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...      0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...      0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...      0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                       0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...      0.0   \n",
       "\n",
       "                                                                                                                                                        abcnewsbayarea  \\\n",
       "processed_tweets                                                                                                                                                         \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...             0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...             0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...             0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                              0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...             0.0   \n",
       "\n",
       "                                                                                                                                                        abdirashidm  \\\n",
       "processed_tweets                                                                                                                                                      \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...          0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...          0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...          0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                           0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...          0.0   \n",
       "\n",
       "                                                                                                                                                        ...  \\\n",
       "processed_tweets                                                                                                                                        ...   \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...  ...   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...  ...   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...  ...   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                   ...   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...  ...   \n",
       "\n",
       "                                                                                                                                                        zhengli  \\\n",
       "processed_tweets                                                                                                                                                  \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...      0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...      0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...      0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                       0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...      0.0   \n",
       "\n",
       "                                                                                                                                                        zhou  \\\n",
       "processed_tweets                                                                                                                                               \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...   0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...   0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...   0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                    0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...   0.0   \n",
       "\n",
       "                                                                                                                                                        zimbabwe  \\\n",
       "processed_tweets                                                                                                                                                   \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...       0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...       0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...       0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                        0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...       0.0   \n",
       "\n",
       "                                                                                                                                                        zimbabwean  \\\n",
       "processed_tweets                                                                                                                                                     \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...         0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...         0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...         0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                          0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...         0.0   \n",
       "\n",
       "                                                                                                                                                        zls  \\\n",
       "processed_tweets                                                                                                                                              \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...  0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...  0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...  0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                   0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...  0.0   \n",
       "\n",
       "                                                                                                                                                        zombie  \\\n",
       "processed_tweets                                                                                                                                                 \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...     0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...     0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...     0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                      0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...     0.0   \n",
       "\n",
       "                                                                                                                                                        zone  \\\n",
       "processed_tweets                                                                                                                                               \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...   0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...   0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...   0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                    0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...   0.0   \n",
       "\n",
       "                                                                                                                                                        zoonotic  \\\n",
       "processed_tweets                                                                                                                                                   \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...       0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...       0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...       0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                        0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...       0.0   \n",
       "\n",
       "                                                                                                                                                        zorrillaalex  \\\n",
       "processed_tweets                                                                                                                                                       \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...           0.0   \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...           0.0   \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...           0.0   \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                            0.0   \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...           0.0   \n",
       "\n",
       "                                                                                                                                                        zxrnoh  \n",
       "processed_tweets                                                                                                                                                \n",
       "['amazing', 'timelapse', 'china', 'completes', 'first', 'two', 'hospital', 'wuhan', 'within', 'day', 'bed', 'medical', 'staff', 'treat', 'infected'...     0.0  \n",
       "['bloomberg', 'scoop', '#coronavirus', 'impact', 'chinese', 'oil', 'demand', 'said', 'dropped', 'three', 'million', 'barrel', 'day', 'total', 'cons...     0.0  \n",
       "['become', 'ill', 'worry', 'stuff', 'related', 'existing', 'gi', 'issue', 'coronavirus', 'saw', 'email', 'concerning', 'visit', 'provedence', 'hosp...     0.0  \n",
       "['nprhealth', 'usa', 'hospital', 'unprepared', 'quickly', 'spreading', 'coronavirus']                                                                      0.0  \n",
       "['read', 'zerohedge', 'piece', 'coronavirus', 'phd', 'mol', 'bio', 'doubt', 'engineered', 'bioweapon', 'natural', 'statistically', 'improbably', 's...     0.0  \n",
       "\n",
       "[5 rows x 5740 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2996, 5740)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 2,996 tweets, there is a total of 5,704 unique words. This includes hashtags and tagged handles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"processed_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tweet_list = train_df.processed_tweets.apply(('').join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          ['switchfoot', 'httptwitpiccom', '2y1zl', 'awww', 'thats', 'bummer', 'shoulda', 'got', 'david', 'carr', 'third', 'day']\n",
       "1                  ['upset', 'cant', 'update', 'facebook', 'texting', 'might', 'cry', 'result', 'school', 'today', 'also', 'blah']\n",
       "2                                          ['kenichan', 'dived', 'many', 'time', 'ball', 'managed', 'save', 'rest', 'go', 'bound']\n",
       "3                                                                               ['whole', 'body', 'feel', 'itchy', 'like', 'fire']\n",
       "4                                                                      ['nationwideclass', 'behaving', 'im', 'mad', 'cant', 'see']\n",
       "                                                                    ...                                                           \n",
       "1599995                                                                              ['woke', 'school', 'best', 'feeling', 'ever']\n",
       "1599996                                           ['thewdbcom', 'cool', 'hear', 'old', 'walt', 'interview', 'httpblipfm', '8bmta']\n",
       "1599997                                                                             ['ready', 'mojo', 'makeover', 'ask', 'detail']\n",
       "1599998                                           ['happy', '38th', 'birthday', 'boo', 'alll', 'time', 'tupac', 'amaru', 'shakur']\n",
       "1599999                                             ['happy', '#charitytuesday', 'thenspcc', 'sparkscharity', 'speakinguph', '4h']\n",
       "Name: processed_tweets, Length: 1600000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(train_tweet_list)\n",
    "dense_matrix = tfidf_matrix.todense()\n",
    "dense_list = dense_matrix.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(dense_list, columns = vectorizer.get_feature_names(), index=tweet_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-learn-env]",
   "language": "python",
   "name": "conda-env-anaconda3-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
